{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLossesKeras\n",
    "# import keras models\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# set random seed globally\n",
    "my_seed = 21\n",
    "from numpy.random import seed\n",
    "seed(my_seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(my_seed) \n",
    "# tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       fM3Trans   fAlpha     fDist class  \n",
       "0       -8.2027  40.0920   81.8828     g  \n",
       "1       -9.9574   6.3609  205.2610     g  \n",
       "2      -45.2160  76.9600  256.7880     g  \n",
       "3       -7.1513  10.4490  116.7370     g  \n",
       "4       21.8393   4.6480  356.4620     g  \n",
       "...         ...      ...       ...   ...  \n",
       "19015    2.8766   2.4229  106.8258     h  \n",
       "19016   -2.9632  86.7975  247.4560     h  \n",
       "19017   -9.4662  30.2987  256.5166     h  \n",
       "19018  -63.8389  84.6874  408.3166     h  \n",
       "19019   31.4755  52.7310  272.3174     h  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data',\n",
    "                 names = ['fLength','fWidth','fSize','fConc','fConc1','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       fM3Trans   fAlpha     fDist  class  \n",
       "0       -8.2027  40.0920   81.8828      0  \n",
       "1       -9.9574   6.3609  205.2610      0  \n",
       "2      -45.2160  76.9600  256.7880      0  \n",
       "3       -7.1513  10.4490  116.7370      0  \n",
       "4       21.8393   4.6480  356.4620      0  \n",
       "...         ...      ...       ...    ...  \n",
       "19015    2.8766   2.4229  106.8258      1  \n",
       "19016   -2.9632  86.7975  247.4560      1  \n",
       "19017   -9.4662  30.2987  256.5166      1  \n",
       "19018  -63.8389  84.6874  408.3166      1  \n",
       "19019   31.4755  52.7310  272.3174      1  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding the target column\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['class'])\n",
    "label\n",
    "\n",
    "encoded_df = df.copy()\n",
    "encoded_df.drop(\"class\", axis=1, inplace=True)\n",
    "encoded_df[\"class\"] = label\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the total number of classes\n",
    "nb_classes = len(encoded_df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15216, 10)\n",
      "(15216,)\n",
      "(3804, 10)\n",
      "(3804,)\n"
     ]
    }
   ],
   "source": [
    "# Creating target and features\n",
    "X = encoded_df.drop(['class'], axis=1)\n",
    "y = encoded_df['class']\n",
    "\n",
    "# scale the variables\n",
    "sc = StandardScaler() \n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "# Split into train and test set and normalize data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size = 0.2) #, random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSequentialModel():\n",
    "    # Build a Sequential Model.\n",
    "    model = Sequential()\n",
    "    # model.add(Flatten(input_shape=(10, 1)))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    model.add(Dense(392, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(196, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(98, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # raise NotImplementedError()\n",
    "    # Output Layer\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional Activation Functions to test\n",
    "- Logistic regression hypothesis (Sigmoid)\n",
    "- Hyperbolic Tangent (tanh) # rescaled sigmoid to (-1, +1)\n",
    "- Rectified Linear Unit (ReLU)\n",
    "- Gaussian Error Linear Unit (GELU) # smoothed ReLU\n",
    "- Normalized Exponential Function (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = buildSequentialModel()\n",
    "# compile model\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "15/15 [==============================] - 2s 18ms/step - loss: 0.5449 - accuracy: 0.7397 - val_loss: 0.4026 - val_accuracy: 0.8141\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8172 - val_loss: 0.3654 - val_accuracy: 0.8454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19b031a1b80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=1024, epochs=2, verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8454\n",
      "Your CV accuracy score is: 0.8454258441925049\n"
     ]
    }
   ],
   "source": [
    "#scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Your CV accuracy score is:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your classifier got the following 588 items wrong out of 10,000:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   3,   12,   13,   20,   23,   33,   35,   36,   41,   47,   75,\n",
       "         77,   86,   89,   92,   94,   96,  126,  129,  138,  147,  154,\n",
       "        155,  156,  170,  172,  175,  179,  188,  189,  206,  207,  209,\n",
       "        210,  214,  221,  232,  239,  247,  257,  258,  263,  268,  277,\n",
       "        298,  302,  305,  306,  310,  315,  316,  317,  328,  337,  346,\n",
       "        352,  353,  356,  363,  364,  367,  369,  376,  385,  391,  392,\n",
       "        406,  410,  427,  431,  432,  434,  440,  457,  459,  469,  472,\n",
       "        484,  487,  488,  494,  500,  503,  507,  524,  528,  531,  535,\n",
       "        538,  554,  560,  561,  565,  575,  578,  593,  604,  615,  620,\n",
       "        621,  627,  628,  634,  650,  659,  661,  662,  667,  668,  676,\n",
       "        681,  688,  689,  690,  693,  697,  705,  710,  722,  723,  724,\n",
       "        726,  734,  742,  753,  755,  756,  771,  784,  786,  797,  799,\n",
       "        803,  815,  818,  823,  824,  833,  840,  860,  861,  864,  867,\n",
       "        880,  885,  889,  890,  896,  905,  907,  935,  949,  968,  976,\n",
       "        978,  990,  997,  998, 1001, 1013, 1014, 1018, 1034, 1043, 1046,\n",
       "       1050, 1075, 1078, 1079, 1083, 1084, 1089, 1094, 1097, 1112, 1115,\n",
       "       1148, 1154, 1159, 1162, 1169, 1172, 1175, 1176, 1178, 1182, 1185,\n",
       "       1198, 1200, 1207, 1211, 1223, 1225, 1230, 1242, 1243, 1247, 1262,\n",
       "       1263, 1265, 1274, 1287, 1293, 1304, 1319, 1321, 1331, 1332, 1347,\n",
       "       1350, 1358, 1361, 1362, 1373, 1377, 1378, 1381, 1385, 1387, 1392,\n",
       "       1399, 1406, 1427, 1441, 1451, 1457, 1462, 1466, 1467, 1488, 1490,\n",
       "       1492, 1495, 1524, 1530, 1531, 1538, 1539, 1559, 1567, 1572, 1578,\n",
       "       1586, 1589, 1592, 1594, 1597, 1602, 1610, 1612, 1627, 1629, 1634,\n",
       "       1639, 1640, 1647, 1653, 1659, 1666, 1673, 1679, 1686, 1689, 1691,\n",
       "       1692, 1709, 1710, 1712, 1718, 1721, 1727, 1731, 1732, 1744, 1746,\n",
       "       1758, 1778, 1783, 1786, 1787, 1794, 1801, 1810, 1826, 1843, 1847,\n",
       "       1850, 1864, 1871, 1873, 1874, 1894, 1896, 1897, 1901, 1913, 1920,\n",
       "       1928, 1930, 1932, 1941, 1954, 1962, 1963, 1964, 1966, 1970, 1980,\n",
       "       1988, 1992, 1993, 1999, 2004, 2014, 2020, 2021, 2024, 2030, 2035,\n",
       "       2048, 2054, 2057, 2058, 2065, 2066, 2077, 2079, 2083, 2090, 2093,\n",
       "       2099, 2102, 2104, 2107, 2108, 2115, 2130, 2140, 2146, 2147, 2158,\n",
       "       2162, 2173, 2177, 2180, 2183, 2189, 2193, 2194, 2199, 2212, 2222,\n",
       "       2241, 2242, 2246, 2251, 2262, 2268, 2276, 2277, 2282, 2308, 2315,\n",
       "       2320, 2324, 2333, 2354, 2362, 2374, 2377, 2380, 2381, 2396, 2403,\n",
       "       2414, 2417, 2419, 2423, 2426, 2452, 2455, 2458, 2461, 2467, 2470,\n",
       "       2477, 2487, 2488, 2494, 2496, 2515, 2521, 2528, 2559, 2561, 2562,\n",
       "       2566, 2576, 2592, 2595, 2604, 2612, 2621, 2623, 2625, 2636, 2643,\n",
       "       2646, 2648, 2650, 2657, 2662, 2684, 2690, 2708, 2710, 2727, 2729,\n",
       "       2736, 2738, 2742, 2757, 2767, 2782, 2790, 2791, 2793, 2798, 2800,\n",
       "       2809, 2811, 2832, 2847, 2854, 2857, 2860, 2861, 2862, 2872, 2874,\n",
       "       2884, 2887, 2893, 2910, 2921, 2926, 2928, 2934, 2941, 2946, 2949,\n",
       "       2967, 2977, 2985, 2991, 2993, 2996, 3002, 3004, 3008, 3010, 3011,\n",
       "       3013, 3015, 3023, 3024, 3027, 3028, 3030, 3054, 3055, 3063, 3066,\n",
       "       3072, 3073, 3081, 3083, 3094, 3096, 3101, 3102, 3107, 3115, 3120,\n",
       "       3128, 3145, 3147, 3158, 3174, 3186, 3192, 3198, 3202, 3209, 3212,\n",
       "       3219, 3224, 3235, 3243, 3254, 3268, 3269, 3272, 3273, 3274, 3280,\n",
       "       3287, 3290, 3294, 3299, 3306, 3320, 3325, 3329, 3331, 3334, 3335,\n",
       "       3343, 3355, 3356, 3364, 3365, 3368, 3371, 3381, 3389, 3401, 3407,\n",
       "       3428, 3436, 3448, 3449, 3464, 3480, 3485, 3486, 3490, 3491, 3493,\n",
       "       3499, 3502, 3503, 3504, 3514, 3528, 3533, 3534, 3537, 3538, 3539,\n",
       "       3546, 3556, 3558, 3566, 3580, 3592, 3593, 3594, 3600, 3601, 3602,\n",
       "       3613, 3615, 3625, 3632, 3635, 3638, 3649, 3663, 3669, 3675, 3679,\n",
       "       3696, 3697, 3699, 3700, 3703, 3707, 3716, 3725, 3731, 3735, 3741,\n",
       "       3766, 3775, 3779, 3791, 3800], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The predict_classes function outputs the highest probability class\n",
    "# according to the trained classifier for each input example.\n",
    "predicted_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "\n",
    "# Identify which examples were correctly and incorrectly classified.\n",
    "#correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "#incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "\n",
    "correct_indices = np.nonzero(predicted_classes == y_test.values)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test.values)[0]\n",
    "\n",
    "\n",
    "# Count the number of incorrectly classified examples of 10,000 test cases\n",
    "len(incorrect_indices)\n",
    "print(\"Your classifier got the following \" + str(len(incorrect_indices)) + \" items wrong out of 10,000:\")\n",
    "incorrect_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
